
---
# T3 - OpenMP

[Atrás](../README.md)

---
## Definiciones

- **Proceso**
	- Ejecuta un programa en su espacio de memoria.
	- Puede estar formado por varios hilos.
	- Los hilos se ejecutan en los núcleos que estén disponibles de forma no determinista.
	- Los hilos tienen recursos propios y otros compartidos a nivel de proceso.
- **Race conditions**
	- Situación donde el resultado depende del orden de ejecución de los hilos.
- **Operación atómica**
	- Operación indivisible que se debe ejecutar sin interrupciones.
- **Sección crítica**
	- Bloque de codigo que solo puede ser ejecutado por un hilo de cada vez.
- **Sincronización**
	- Los hilos del mismo proceso se comunican entre ellos.
	- Uso de barreras y/o ejecución ordenada

---
## Arquitectura

### Jerarquías de memoria

A más cercanas al procesador las memorias son más pequeñas pero más rápidas.
En orden:
1. **Registros** (núcleo)
2. **L1 Caché** (núcleo)
3. **L2 Caché** (núcleo o conjunto de núcleos)
4. **L3 Caché** (chip - procesador)
5. **Memoria principal** (sistema)
6. **Almacenamiento secundario** (sistema)
### Memoria
- **UMA (Uniform Memory Access)**
	- Todos los procesadores comparten el mismo espacio de memoria.
	- Mismo tiempo de acceso a memoria para todos los procesadores y direcciones.
- **NUMA (Non-Uniform Memory Access)**
	- Cada procesador tiene:
		- Memoria local (propia y rapida) 
		- Memoria remota (compartida y lenta)
	- Tiempo de acceso depende de donde estén almacenados.
### Otros

- **Coherencia y Consistencia (CC)** de información.
	- Compartir la misma dirección de memoria es fuente de conflictos
- **Contención**
	- Varios procesadores intentan acceder a datos comunes o en el mismo bloque de memoria.
- ***False Sharing***
	- Cada procesador tiene una copia local de un dato.
	- Para mantener coherencia, si uno escribe un dato, se invalida en los demás.

---
## OpenMP - Introducción
### Variables de entorno
```bash
# Fija el número de hilos para regiones paralelas.
export OMP_NUM_THREADS=8

# Activa/Desactiva el paralelismo anidado.
export OMP_NESTED=true

# Activa/Desactiva el ajuste dinámico del Nº de hilos dependiendo de la carga del sistema.
export OMP_DYNAMIC=false

# Indica la forma de repartir el trabajo en los hilos. Se verá a en WC.
export OMP_SCHEDULE="guided,4"
```
### Uso
```C++
// Incluimos la libreria
#include <omp.h>

// Puede tener 0, 1 o más clausulas.
#pragma omp <directiva> [clausula [...]]
{
	...
}

// Compilación condicionada (solo con funciones OMP)
#ifdef _OPENMP
	...
#endif
```

Para compilar se usa: `gcc -fopenmp`
### Funciones
Tienen prioridad sobre las variables de entorno.
```C++
// Gestiona el ajuste dinámico de hilos. 0 OFF, 1 ON.
int omp_get_dynamic(void);
void omp_set_dynamic(int valor);

// Gestiona el paralelismo anidado. 0 OFF, 1 ON.
int omp_get_nested(void);
void omp_set_nested(int valor);

// Gestiona el número de hilos de las regiones paralelas.
void omp_set_num_threads(int num_threads);
int omp_get_num_threads(void);

// Devuleve 1 si dentro de región paralela.
int omp_in_parallel(void);

// Devuelve el número de procesadores físicos disponibles.
int omp_get_num_procs(void);

// Devuelve el número máximo de hilos que se pueden usar.
int omp_get_max_threads(void);

// Devuelve el identificador de hilo.
int omp_get_thread_num(void);
```

---
## OpenMP - Constructor `parallel`
### Definición
- Paraleliza la región que le sigue. Mismo código en todos los hilos.
- Hay un hilo maestro con `ID = 0`.El resto de hilos se numeran de $1$ a $n-1$.
### Cláusulas
- `if(condicion)`.
	- Paraleliza solo si se cumple la condición. Sino se ejecuta en serie.
- `default(share|none)`.
	- Define si las variables son compartidas o privadas por defecto.
	- Si no se especifica son compartidas.
- `shared(var1, var2, ...)`.
	- Especifica las variables compartidas.
	- Solo se usa si se especifica `default(none)`.
- `private(var1, var2, ...)`.
	- Especifica las variables privadas.
	- Pueden o no estar inicializadas al principio de la región.
- `firstprivate(var1, var2, ...)`
	- Especifica las variables privadas.
	- Se inicializan al valor que tenían antes de la región paralela.
- `num_threads(n)`.
	- Región paralela con $n$ hilos.
	- Tiene prioridad sobre los definidos con variables de entorno o funciones.
- `copyin(var1, var2, ...)`
	- Copia el valor en el hilo maestro al resto de hilos.
	- Si se encuentra en una región paralela tiene efecto en la siguiente.
- `reduction(op : var)`
	- Realiza una operación de reducción sobre unas variables de forma segura.
	- `op` puede tener los valores: `+`, `*`, `-`, `&`, `|`, `^`, `&&`, `||`, `max` y `min`

---
## OpenMP - Worksharing Constructors (WS)

### Definición
- Directivas que dividen un trabajo automáticamente para que pueda ejecutarse en varios hilos.
- No garantizan paralelismo. Para eso requieren de una cláusula `parallel`.
- Garantizan sincronismo de salida.
### Cláusulas
- `private()`, `firstprivate()`, `reduction()`, `shared()`
	- Ya vistas en `parallel`.
- `nowait`
	- Elimina el sincronismo de salida.
- `ordered`
	- Las iteraciones se ejecutan en el orden original (secuencial).
- `schedule(tipo, n)`
	- Controla como se distribuye el trabajo en los hilos. Dependiendo del tipo:
		- `static` (default). Asigna el trabajo antes de ejecutar.
			- Se divide el trabajo de forma cíclica entre los hilos en bloques de $n$.
			- Si no se especifica $n$ se divide a partes iguales.
		- `dynamic`. Estrategia First Come First Served
			- Se asigna $n$ iteraciones a cada bloque y cuando termina se le asignan otros $n$.
			- Si no se especifica $n=1$.
		- `guided`. Similar a dynamic.
			- El tamaño de bloque que se asigna va decreciendo exponencialmente.
			- El tamaño mínimo de bloque es $n$ o $1$ si no se especifica.
		- `runtime`. Se define en tiempo de ejecución por la variable de entorno.
- `collapse(n)`
	- Fusiona $n$ bucles anidados (canónicos) para su distribución en hilos.
- `lastprivate(var1, var2, ...)`
	- La última iteración copia el valor de las variables locales a su correspondiente global.
### FOR

- No implica paralelismo. Solo "parte" en bloques.
- Por defecto la única variable privada es la de control.
- Permite una cláusula extra: `linear(var1 : step1, var2 : step2, ...)`
	- Si hay alguna variable que crezca de forma linear dentro de bucle. Ejemplo:`x+=2`.
	- Permite que el compilador lo optimize.

```C++
#pragma omp parallel // Sin el no hay paralelismo
#pragma omp for
for(i=0; i < 10; i++) {...}
```

### SECTIONS

- No implica paralelismo. Solo define los bloques que pueden ejecutarse en paralelo.
- Todas las secciones son precedidas por `section` menos la primera.
- Las secciones se ejecutan una sola vez.
```C++
#pragma omp parallel // Sin el no hay paralelismo
#pragma omp sections
{
	... // Sección 1
	#pragma omp section
	... // Sección 2
	#pragma omp section
	... // Sección 3
}
```

### SINGLE

- El primer hilo que lo alcance lo ejecuta y el resto espera.

```C++
#pragma omp parallel // Sin el no hay paralelismo
{
	... // se ejecuta un código en paralelo
	
	#pragma omp single
	{
		... // Esto lo ejecuta solo el primer hilo en llegar.
	}
	
	... // Luego siguen ejecutando todos.
}
```

---
## OpenMP - Combined Constructors (CC)

- Combinan los Worksharing constructors con el parallel.

```C++
#pragma omp parallel for
for(i=0; i<10; i++)
{
	...
}

#pragma omp parallel sections
{
	...
	#pragma omp section
	...
}
```

---
## OpenMP - Constructor SIMD (CSIMD)
### Definición
- Solo son aplicables sobre bucles en forma canónica.
- Usa instrucciones SIMD para hacer varias iteraciones del bucle en un solo ciclo.
### Cláusulas
- `collapse`, `reduction`, `lastprivate`, `linear` y `private`
	- Ya vistas
- `simdlen(n)`
	- Ejecuta $n$ iteraciones en un mismo ciclo (concurrentemente).
- `safelen(n)`
	- Garantiza que no hay dependencias en un radio de $n$ con respecto a cada iteración $i$.
	- La iteración $i$ no puede depender de cualquier iteración $k$  $i-n < k < i+n$.
- `aligned(ptr : n)`
	- Indica que los valores del puntero `ptr` están alineados en memoria cada $n$ bytes.

---
## OpenMP - CTASK
### Definición
- El hilo que lo ejecute crea la tarea. No necesariamente la ejecuta él, ni implica paralelismo.
- Cada tarea es independiente y puede ser ejecutada por cualquier hilo.
- Las tareas se ejecutan en un *Task Synchronization Point* (TSP), no donde se ven el el código.
- Las variables son privadas por defecto.
	- SI ESTA DENTRO DE OTRA DIRECTIVA SON SHARED POR DEFECTO.
### Cláusulas
- `firstprivate`, `shared`, `default`, `private`, `if`
	- Ya vistas
- `untied`
	- Hace que las tareas no se "aten" a un hilo 
	- Pueden ejecutarse por cualquier hilo (incluso una vez empezadas).
- `final(condicion)`
	- Indica que la tarea no puede generar más tareas si se cumple la condición.
- `depend(in: var)` y/o  `depend(out: var)`
	- Indica dependencias en las tareas.
	- Asegura la correcta ejecución. (en orden)
- `mergeable`
	- Se puede fusionar con la tarea creadora.
- `priority(n)`
	- Cuanto mayor sea $n$ mayor prioridad y por tanto antes se ejecutará.
### Además
- `#pragma omp taskyield`
	- Suspende la ejecución de la tarea.
- `#pragma omp taskwait`
	- Espera a que terminen todas las tareas pendientes. (TSP)
- `#pragma omp taskgroup {}`
	- Agrupa un conjunto de tareas.
	- Espera a que terminen.

[How to Get OpenMP Tasks To Do Your Work (OpenMP Webinar)](https://www.youtube.com/watch?v=zdNqfG3yBew)

---
## Constructores de sincronización
### MASTER
- Solo es ejecutado por el hilo maestro (hilo 0).
- Si hay una región anidada se ejecuta varias veces.

```C++
#pragma omp parallel
{
	#pragma omp master
	{
		... // Esto lo ejecuta solo el hilo 0 de cada región paralela.
	}
}
```
### BARRIER
- Sincroniza todos los hilos del equipo.
```C++
#pragma omp parallel
{
	...
	#pragma omp barrier
	...
}
```
### CRITICAL
- Bloque de codigo que no puede ser ejecutado a la vez por varios hilos.
- Si es una sección paralela todos los hilos la ejecutan pero no a la vez.
- Si hay varias regiones criticas estas tampoco se pueden ejecutar a la vez.
- Se les puede dar un nombre para distinguirlas y que se puedan ejecutar a la vez
```C++
#pragma omp parallel
{
	
	#pragma omp critical (region1)
	{
		... // Solo la ejecuta un hilo de cada vez.
	}
	
	#pragma omp critical (region2)
	{
		... // Se puede ejecutar en paralelo a la región 1.
	}

	#pragma omp critical (region1)
	{
		... // No se puede ejecutar en paralelo a la región 1.
	}
}
```
### ATOMIC
- Similar a secciones críticas pero más eficiente.
- Solo vale para expresiones atómicas: `read`, `write`, `update` (default) y `capture`
```C++
#pragma omp parallel shared(x)
{
	int var;
	
	#pragma atomic read
	var = x;
	
	#pragma atomic write
	x = var;
	
	// Comportamiento por defecto si no se especifica nada
	#pragma omp atomic
	x += 1;
	
	#pragma omp atomic capture
	{
		previa = x; // Combina read + update
		x += 2;
	}
}
```
---
## Medición de tiempos
```C++
double omp_get_wtime(void); // Obtiene el tiempo actual
double omp_get_wtick(void); // Obtiene la precisión del reloj
```
---
## Cerrojos
```C++
omp_lock_t cerrojo; // Creamos la variable cerrojo
omp_init_lock(&cerrojo); // Inicializamos el cerrojo

#pragma omp parallel
{
	... // Algún código paralelo

	// Adquirimos el cerrojo. Solo un hilo entra de cada vez. El resto espera.
	omp_set_lock(&cerrojo); 
	... // Sección critica/protegida
	omp_unset_lock(&cerrojo); // Liberamos el cerrojo. Otro hilo podrá entrar.
	
}

omp_destroy_lock(&cerrojo); // Destruimos el cerrojo
```

```C++
// Alternativa
#pragma omp parallel
{
	...
	
	// El que adquiere el cerrojo no bloquea al resto de hilos.
	if (omp_test_lock(&cerrojo)) {
		... // Si consigue adquirir el cerrojo hace esto.
	} else {
		... // Si no consigue adquirir el cerrojo hace esto.
	}
}
```


```C++
int i;

#pragma omp parallel for
for(i=0; i<n; i++)
{
	#pragma omp atomic
	histograma[datos[i]]++;
}
```
---
## Otros constructores / cláusulas
### FLUSH
- `#pragma omp flush(var1, var2, ...)`
- Al final de cada región de omp se actualizan las variables compartidas (menos con `nowait`).
- Obliga a actualizarlas antes de tiempo.
### threadprivate
- `#pragma omp threadprivate(var1, var2, ...)`
- Crea una copia local de unas variables globales.
---
