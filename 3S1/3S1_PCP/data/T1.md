
---
# T1 - Análisis de Rendimiento

[Atrás](../README.md)

---
## Tiempo de Ejecución Sequencial  $t(n)$ 

$$
\sum_{i=1}^n 1 = n \quad\quad;\quad\quad \sum_{i=1}^n i \approx \frac{n^2}{2} \quad\quad;\quad\quad \sum_{i=1}^n i^2 \approx \frac{n^3}{3}
$$
---
## Tiempo de Ejecución Paralelo $t(n, p)$ 

- Tiempo máximo teórico cuando $t(n, p) = \frac{t(n)}{p}$
- $T(n, p) = T_{ar}(n, p) + T_{co}(n, p) - T_{sol}(n, p) + T_{ov}(n, p)$
	- $T_{ar}$ el tiempo de computación.
	- $T_{co}$ el tiempo de comunicaciones.
	- $T_{sol}$ el tiempo de solapamiento entre $T_{ar}$ y $T_{co}$ (despreciamos)
	- $T_{ov}$ el tiempo de sobrecargas (esperas, creación de procesos... ) (despreciamos)
---
## FLOP / FLOPs
### FLOP
- Es el coste de una operación básica ($+$ , $-$ , $\times$ , $/$ ) en coma flotante.
- Las  otras operaciones (como las enteras) no se contabilizan.
### FLOPs
- Es el número de FLOP por segundo.
- Theorical Peak double precision floating point Performance $TPP_{dp}$ se mide en GFLOPs
- $TPP_{SP} \:\text{(single precision)} = 2\times TPP_{dp}$
$$
\begin{align}
&TPP_{dp} = \text{Nº cores} \times \text{clock}_{\:GHz} \times \frac{\text{nº flop}}{\text{ciclo}} \\\\
&TPP_{dp} = \text{Nº cores} \times \text{clock}_{\:GHz} \times (\text{SIMD/AVX})
\end{align}
$$

---

## Otras medidas relativas

| Nombre                      | Ecuación                         | Descripción                                    |
| --------------------------- | -------------------------------- | ---------------------------------------------- |
| **Coste**                   | $C(n, p) = p \times T(n, p)$     | Coste en paralelo                              |
| **Sobrecarga u *Overhead*** | $T_0(n, p) = C(n, p) - T(n)$     | Tiempo extra que supone trabajar en paralelo   |
| **Speedup**                 | $S(n, p) = \frac{T(n)}{T(n, p)}$ | Mejora al paralelizar. Si igual a $p$ lineal.  |
| **Eficiencia**              | $E(n, p) = \frac{S(n)}{p}$       | Grado de aprovechamiento. Si constante escala. |

---
## Ley de Amdahl

- **Tpo sequencial** $\to t(n) = \alpha(n) + \beta(n)$
	- $\alpha(n)$ = tiempo no paralelizable.
	- $\beta(n)$ = tiempo paralelizable.
- **Tipo paralelo** $\to t(n) = \alpha(n) + \frac{\beta(n)}{p}$
- **Speedup maximo** $\to 1 + \frac{\beta(n)}{\alpha(n)}$
- $S(n, p) = \frac{1}{(1 - PF)+ \frac{PF}{p}}$ siendo $PF$ el % de tiempo paralelizable.
---
## Eficiencia escalada

$$E_{esc}\:(W, r) = \frac{T(W)}{T(rW, r)}$$

Donde $r$ es una constante cualquiera usada para estudiar la escalabilidad.

---
## Isoeficiencia
$$I(W, p) = \frac{p\times T(n , p) - T(n)}{T(n)} = \frac{T_0(n, p)}{T(n)} = \frac{O(p^r)}{O(p^s)}$$
Si $r \leq s$ el algoritmo escala.

Para resolverlo calculamos $I(W, p)$ y dividimos en dos:
$$
\begin{aligned}
&W = \text{orden del problema u } O(\:T(n)\:)\\\\
&I_{t_s} : W \propto K \times \text{constantes que multiplican }  t_s\\
&I_{t_w} : W \propto K \times \text{constantes que multiplican }  t_w
\end{aligned}
$$
Si el $t_s$ o el $t_w$ es de orden mayor  que W, el algoritmo NO escala

---
## Resolver problemas escalabilidad
1. $t(n) = n \times t_c$
	1. $n$ = Numero total de "bolitas".
2. $t(n, p) = T_{ar}(n, p) + T_{co}(n, p)$
	1. $T_{ar}(n, p) = n \times t_c$ 
		1. Siendo $n$ el número de flop y $t_c$ el tiempo por flop
		2. $n$ = número de bolas por recuadro.
	2. $T_{co}(n, p) = \alpha \times(t_s + \beta \times t_w)$
		1. Siendo $t_s$ la latencia y $t_w$ el ancho de banda
		2. $\alpha$ = numero de flechas salientes/entrantes recuadros minimizados.
		3. $\beta$ = número de líneas entre bolas dentro de distintos recuadros.
3. Si $E(n, p) = \frac{T(n)}{p\times T(n,p)} = cte$  entonces escala.
4. Si no $I(W, p) = \frac{p\times T(n , p) - T(n)}{T(n)}$ y estudiamos orden.

---
